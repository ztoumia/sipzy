# Scraper de TorrÃ©facteurs FranÃ§ais

Ce script Python permet de scraper automatiquement les sites web des torrÃ©facteurs franÃ§ais pour extraire les informations sur leurs cafÃ©s.

## ğŸš€ Installation

1. Installer les dÃ©pendances Python :
```bash
pip install -r requirements.txt
```

## ğŸ“‹ Utilisation

1. Assurez-vous que le fichier `torrefacteurs-france.csv` est dans le mÃªme dossier

2. ExÃ©cuter le script :
```bash
python scrape_roasters.py
```

3. Le script va :
   - Lire tous les torrÃ©facteurs du CSV
   - Visiter chaque site web
   - Chercher les pages de produits/cafÃ©s
   - Extraire automatiquement les informations
   - GÃ©nÃ©rer un fichier `coffees-scraped.csv` avec les rÃ©sultats

## ğŸ“Š DonnÃ©es extraites

Le script essaie d'extraire automatiquement :
- **Nom du cafÃ©**
- **Origine** (pays)
- **Processus** (Washed, Natural, Honey, etc.)
- **Gamme de prix** ($, $$, $$$, $$$$)
- **Description**
- **URL de l'image**
- **Notes de dÃ©gustation** (Citrus, Chocolate, etc.)

## âš™ï¸ Configuration

Vous pouvez modifier les paramÃ¨tres dans le script :
- `DELAY_BETWEEN_REQUESTS` : DÃ©lai entre chaque requÃªte (dÃ©faut: 2 secondes)
- `TIMEOUT` : Timeout des requÃªtes HTTP (dÃ©faut: 10 secondes)
- Mots-clÃ©s pour la dÃ©tection d'origines, processus, notes

## âš ï¸ Limitations

- Le scraping web est fragile : chaque site a sa propre structure
- Certaines informations peuvent ne pas Ãªtre extraites correctement
- Le script respecte un dÃ©lai entre les requÃªtes pour ne pas surcharger les serveurs
- Les sites avec JavaScript dynamique ne sont pas supportÃ©s (nÃ©cessiterait Selenium)
- VÃ©rifiez toujours les donnÃ©es extraites avant de les importer

## ğŸ”§ AmÃ©liorations possibles

- Ajouter le support de Selenium pour les sites JavaScript
- CrÃ©er des extracteurs spÃ©cifiques par torrÃ©facteur
- AmÃ©liorer la dÃ©tection des variÃ©tÃ©s et altitudes
- Ajouter un systÃ¨me de cache pour Ã©viter de re-scraper
- ImplÃ©menter la dÃ©tection de l'annÃ©e de rÃ©colte

## ğŸ“ Notes

- Le script est conÃ§u pour Ãªtre respectueux des sites web
- Un User-Agent navigateur est utilisÃ©
- Des dÃ©lais sont respectÃ©s entre les requÃªtes
- Consultez les CGU des sites avant de scraper massivement
